import streamlit as st
import pandas as pd
from googleapiclient.discovery import build
import re
from datetime import datetime
import csv
from zoneinfo import ZoneInfo

st.set_page_config(
    page_title="ğŸ“Š YouTube Analyzer",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# é»‘ç™½æç®€æ ·å¼
st.markdown("""
<style>
    .main { background-color: #ffffff; }
    .stApp { background-color: #ffffff; }
    .css-1d391kg { background-color: #000000; }
    .stButton > button {
        background-color: #000000;
        color: #ffffff;
        border: 2px solid #000000;
        border-radius: 4px;
        font-weight: bold;
    }
    .stButton > button:hover {
        background-color: #ffffff;
        color: #000000;
        border: 2px solid #000000;
    }
    .stTextInput > div > div > input {
        border: 2px solid #000000;
        border-radius: 4px;
    }
    h1 { color: #000000; text-align: center; }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 4px;
        border: 1px solid #000000;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

def extract_channel_id(url):
    """ä»YouTubeé¢‘é“URLæå–é¢‘é“ID"""
    patterns = [
        r'youtube\.com/channel/([a-zA-Z0-9_-]+)',
        r'youtube\.com/c/([a-zA-Z0-9_-]+)',
        r'youtube\.com/@([a-zA-Z0-9_-]+)',
        r'youtube\.com/user/([a-zA-Z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def get_channel_info(youtube, channel_input):
    """è·å–é¢‘é“ä¿¡æ¯"""
    try:
        # å¦‚æœæ˜¯å®Œæ•´çš„é¢‘é“ID
        if channel_input.startswith('UC') and len(channel_input) == 24:
            response = youtube.channels().list(
                part='snippet,statistics',
                id=channel_input
            ).execute()
            if response['items']:
                return response['items'][0]
        
        # å°è¯•é€šè¿‡æœç´¢æ‰¾åˆ°é¢‘é“
        search_response = youtube.search().list(
            part='snippet',
            q=channel_input,
            type='channel',
            maxResults=5
        ).execute()
        
        if search_response['items']:
            # æŸ¥æ‰¾æœ€åŒ¹é…çš„é¢‘é“
            for item in search_response['items']:
                channel_id = item['snippet']['channelId']
                channel_response = youtube.channels().list(
                    part='snippet,statistics',
                    id=channel_id
                ).execute()
                
                if channel_response['items']:
                    channel = channel_response['items'][0]
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…
                    custom_url = channel['snippet'].get('customUrl', '').lower()
                    if (channel_input.lower() in custom_url or 
                        custom_url in channel_input.lower()):
                        return channel
            
            # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªç»“æœ
            channel_id = search_response['items'][0]['snippet']['channelId']
            channel_response = youtube.channels().list(
                part='snippet,statistics',
                id=channel_id
            ).execute()
            
            if channel_response['items']:
                return channel_response['items'][0]
                
    except Exception as e:
        print(f"Error getting channel info: {e}")
    
    return None

def get_videos(youtube, channel_id, max_results=100):
    """è·å–é¢‘é“è§†é¢‘"""
    videos = []
    
    # è·å–ä¸Šä¼ æ’­æ”¾åˆ—è¡¨ID
    channel_response = youtube.channels().list(
        part='contentDetails',
        id=channel_id
    ).execute()
    
    uploads_playlist_id = channel_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
    
    # è·å–è§†é¢‘åˆ—è¡¨
    next_page_token = None
    while len(videos) < max_results:
        playlist_response = youtube.playlistItems().list(
            part='snippet',
            playlistId=uploads_playlist_id,
            maxResults=min(50, max_results - len(videos)),
            pageToken=next_page_token
        ).execute()
        
        video_ids = [item['snippet']['resourceId']['videoId'] for item in playlist_response['items']]
        
        # è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯
        videos_response = youtube.videos().list(
            part='snippet,statistics,contentDetails',
            id=','.join(video_ids)
        ).execute()
        
        for video in videos_response['items']:
            videos.append(video)
        
        next_page_token = playlist_response.get('nextPageToken')
        if not next_page_token:
            break
    
    return videos[:max_results]

def parse_duration(duration):
    """è§£æYouTubeæ—¶é•¿æ ¼å¼"""
    match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
    if match:
        hours = int(match.group(1) or 0)
        minutes = int(match.group(2) or 0)
        seconds = int(match.group(3) or 0)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
    return "00:00:00"

def extract_hashtags(description):
    """æå–æè¿°ä¸­çš„æ ‡ç­¾"""
    hashtags = re.findall(r'#\w+', description)
    return ', '.join(hashtags) if hashtags else ''

def detect_voiceover(title, description):
    """ç®€å•çš„é…éŸ³æ£€æµ‹ï¼ˆåŸºäºå…³é”®è¯ï¼‰"""
    voiceover_keywords = ['voiceover', 'narration', 'commentary', 'é…éŸ³', 'è§£è¯´', 'voice over']
    text = (title + ' ' + description).lower()
    return any(keyword in text for keyword in voiceover_keywords)

def main():
    st.title("ğŸ“Š YouTubeé¢‘é“åˆ†æå™¨")
    st.markdown("---")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.markdown("### ğŸ”— é¢‘é“ä¿¡æ¯")
        channel_url = st.text_input("YouTubeé¢‘é“é“¾æ¥", 
                                   value="https://www.youtube.com/@tiffanywangmeditation",
                                   placeholder="https://www.youtube.com/@channelname")
        
    with col2:
        st.markdown("### ğŸ”‘ APIå¯†é’¥")
        api_key = st.text_input("YouTube API Key", 
                               value="AIzaSyDrb_aKdgPLfinkgVJfzdKA9F1fgdF2yrg",
                               type="password")
    
    with col3:
        st.markdown("### ğŸŒ æ—¶åŒºé€‰æ‹©")
        timezone_options = {
            "ç¾å›½å¤ªå¹³æ´‹æ—¶é—´ (PT)": "America/Los_Angeles",
            "ç¾å›½ä¸œéƒ¨æ—¶é—´ (ET)": "America/New_York", 
            "ä¸­å›½æ ‡å‡†æ—¶é—´ (CST)": "Asia/Shanghai",
            "æ—¥æœ¬æ ‡å‡†æ—¶é—´ (JST)": "Asia/Tokyo",
            "è‹±å›½æ—¶é—´ (GMT)": "Europe/London",
            "åè°ƒä¸–ç•Œæ—¶ (UTC)": "UTC"
        }
        selected_tz = st.selectbox("é€‰æ‹©æ—¶åŒº", list(timezone_options.keys()))
        timezone_str = timezone_options[selected_tz]
    
    if st.button("ğŸš€ å¼€å§‹åˆ†æ", use_container_width=True):
        if not api_key:
            st.error("âŒ è¯·å¡«å†™APIå¯†é’¥")
            return
        
        # å¦‚æœæ²¡æœ‰è¾“å…¥é¢‘é“é“¾æ¥ï¼Œä½¿ç”¨é»˜è®¤é¢‘é“
        if not channel_url:
            channel_url = "https://www.youtube.com/@tiffanywangmeditation"
        
        try:
            youtube = build('youtube', 'v3', developerKey=api_key)
            
            with st.spinner("ğŸ” æ­£åœ¨è·å–é¢‘é“ä¿¡æ¯..."):
                # æå–é¢‘é“æ ‡è¯†
                channel_input = extract_channel_id(channel_url)
                if not channel_input:
                    # ä»URLä¸­æå–ç”¨æˆ·å
                    if '@' in channel_url:
                        channel_input = channel_url.split('@')[-1]
                    else:
                        channel_input = channel_url.split('/')[-1]
                
                print(f"Searching for channel: {channel_input}")  # Debugä¿¡æ¯
                
                # è·å–é¢‘é“ä¿¡æ¯
                channel_info = get_channel_info(youtube, channel_input)
                if not channel_info:
                    st.error("âŒ æ— æ³•æ‰¾åˆ°é¢‘é“ï¼Œè¯·æ£€æŸ¥é“¾æ¥")
                    return
                
                channel_id = channel_info['id']
                channel_title = channel_info['snippet']['title']
                video_count = int(channel_info['statistics']['videoCount'])
                
                st.success(f"âœ… æ‰¾åˆ°é¢‘é“: {channel_title}")
                
                # æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>ğŸ“º æ€»è§†é¢‘æ•°</h3>
                        <h2>{video_count:,}</h2>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    subscriber_count = int(channel_info['statistics']['subscriberCount'])
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>ğŸ‘¥ è®¢é˜…è€…</h3>
                        <h2>{subscriber_count:,}</h2>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    view_count = int(channel_info['statistics']['viewCount'])
                    st.markdown(f"""
                    <div class="metric-card">
                        <h3>ğŸ‘€ æ€»è§‚çœ‹é‡</h3>
                        <h2>{view_count:,}</h2>
                    </div>
                    """, unsafe_allow_html=True)
            
            with st.spinner("ğŸ“Š æ­£åœ¨åˆ†æè§†é¢‘æ•°æ®..."):
                # ç¡®å®šè¦è·å–çš„è§†é¢‘æ•°é‡
                max_videos = min(100, video_count)
                videos = get_videos(youtube, channel_id, max_videos)
                
                # å¤„ç†è§†é¢‘æ•°æ®
                video_data = []
                for video in videos:
                    snippet = video['snippet']
                    statistics = video['statistics']
                    content_details = video['contentDetails']
                    
                    # è§£æå‘å¸ƒæ—¥æœŸæ—¶é—´å¹¶è½¬æ¢ä¸ºé€‰å®šæ—¶åŒº
                    pub_datetime_utc = datetime.fromisoformat(snippet['publishedAt'].replace('Z', '+00:00'))
                    if timezone_str == 'UTC':
                        pub_datetime_local = pub_datetime_utc
                        tz_abbr = 'UTC'
                    else:
                        pub_datetime_local = pub_datetime_utc.astimezone(ZoneInfo(timezone_str))
                        tz_abbr = selected_tz.split('(')[-1].replace(')', '')
                    
                    weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][pub_datetime_local.weekday()]
                    formatted_date = f"{pub_datetime_local.strftime('%Y-%m-%d %H:%M')} {tz_abbr} ({weekday_cn})"
                    
                    video_data.append({
                        'title': snippet['title'],
                        'link': f"https://www.youtube.com/watch?v={video['id']}",
                        'view_count': int(statistics.get('viewCount', 0)),
                        'duration': parse_duration(content_details['duration']),
                        'published_date': formatted_date,
                        'description': snippet.get('description', '')[:500],
                        'hashtags': extract_hashtags(snippet.get('description', '')),
                        'is_voiceover': detect_voiceover(snippet['title'], snippet.get('description', ''))
                    })
                
                # å­˜å‚¨æ•°æ®åˆ°session state
                st.session_state.video_data = video_data
                st.session_state.channel_title = channel_title
                st.session_state.analysis_complete = True
                
        except Exception as e:
            st.error(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
                
    # å¦‚æœåˆ†æå®Œæˆï¼Œæ˜¾ç¤ºç»“æœå’Œæ’åºé€‰é¡¹
    if hasattr(st.session_state, 'analysis_complete') and st.session_state.analysis_complete:
        df = pd.DataFrame(st.session_state.video_data)
        
        # æ˜¾ç¤ºç»“æœ
        st.markdown("---")
        
        # æ’åºé€‰æ‹©
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"### ğŸ“‹ è§†é¢‘åˆ—è¡¨ ({len(st.session_state.video_data)} ä¸ªè§†é¢‘)")
        with col2:
            sort_options = {
                "è§‚çœ‹é‡ (é«˜åˆ°ä½)": ("view_count", False),
                "è§‚çœ‹é‡ (ä½åˆ°é«˜)": ("view_count", True),
                "å‘å¸ƒæ—¥æœŸ (æœ€æ–°)": ("published_date", False),
                "å‘å¸ƒæ—¥æœŸ (æœ€æ—©)": ("published_date", True),
                "é…éŸ³æ£€æµ‹ (æœ‰é…éŸ³)": ("is_voiceover", False),
                "é…éŸ³æ£€æµ‹ (æ— é…éŸ³)": ("is_voiceover", True)
            }
            selected_sort = st.selectbox("ğŸ“Š æ’åºæ–¹å¼", list(sort_options.keys()), key="sort_selector")
            sort_column, ascending = sort_options[selected_sort]
            
            # åº”ç”¨æ’åº
            df_sorted = df.sort_values(by=sort_column, ascending=ascending)
        
        # ç”ŸæˆCSVæ–‡ä»¶å
        csv_filename = f"{st.session_state.channel_title.replace(' ', '_')}_videos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.dataframe(
            df_sorted[['title', 'view_count', 'duration', 'published_date', 'is_voiceover']],
            use_container_width=True,
            column_config={
                'title': 'æ ‡é¢˜',
                'view_count': 'è§‚çœ‹é‡',
                'duration': 'æ—¶é•¿',
                'published_date': 'å‘å¸ƒæ—¥æœŸ',
                'is_voiceover': 'é…éŸ³æ£€æµ‹'
            }
        )
        
        # ä¸‹è½½æŒ‰é’® - ä½¿ç”¨æ’åºåçš„DataFrame
        csv_data = df_sorted.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´CSVæ–‡ä»¶",
            data=csv_data.encode('utf-8-sig'),
            file_name=csv_filename,
            mime='text/csv',
            use_container_width=True
        )
        
        st.success(f"âœ… åˆ†æå®Œæˆï¼å…±å¤„ç† {len(st.session_state.video_data)} ä¸ªè§†é¢‘")

if __name__ == "__main__":
    main()